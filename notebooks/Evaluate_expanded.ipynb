{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spectacular-broadcasting",
   "metadata": {},
   "source": [
    "How well did the 2020 ensemble model do on new grants tagged\n",
    "with the new definition of tech - i.e. not just UK based and not just in the health domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opposite-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report,  f1_score, precision_score, recall_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "returning-cover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gallaghe/Code/nutrition-labels\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "little-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nutrition_labels.ensemble_model import EnsembleModel, get_seed_results\n",
    "from nutrition_labels.utils import pretty_confusion_matrix, clean_grants_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-limit",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unexpected-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('data/processed/training_data/210126/training_data.csv')\n",
    "old_training_data = pd.read_csv('data/processed/training_data/200807/training_data.csv')\n",
    "grant_data = pd.read_csv('data/raw/wellcome-grants-awarded-2005-2019.csv')\n",
    "old_ensemble_results = pd.read_csv('data/processed/ensemble/201118/201118_all_ensemble_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-dating",
   "metadata": {},
   "source": [
    "## How many data points were changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "willing-phrase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance code_old</th>\n",
       "      <th>Relevance code_new</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Relevance code_old Relevance code_new  count\n",
       "0                0.0                0.0    151\n",
       "1                0.0                1.0     33\n",
       "2                0.0                nan    699\n",
       "3                1.0                1.0    213\n",
       "4                1.0                nan      1\n",
       "5                nan                0.0    198\n",
       "6                nan                1.0    101"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_training_data = pd.merge(\n",
    "    old_training_data[['Internal ID', 'Relevance code']],\n",
    "    training_data[['Internal ID', 'Relevance code']], \n",
    "    how='outer', on ='Internal ID', suffixes=('_old', '_new'))\n",
    "merged_training_data.fillna('nan').groupby(['Relevance code_old','Relevance code_new']).size().reset_index().rename(columns={0:'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-voice",
   "metadata": {},
   "source": [
    "## Load model and find out how well it transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hybrid-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_cutoff = 0.8\n",
    "precision_cutoff = 0.82\n",
    "recall_cutoff = 0.82\n",
    "after_date = 201022\n",
    "before_date = 201022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gothic-intro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 useful models found\n",
      "There is/are 1 unique split seeds used for these models if this is more than 1 then the ensemble model metrics can be ignored\n"
     ]
    }
   ],
   "source": [
    "ensemble_model = EnsembleModel(\n",
    "    f1_cutoff =f1_cutoff,\n",
    "    precision_cutoff = precision_cutoff,\n",
    "    recall_cutoff = recall_cutoff,\n",
    "    before_date = before_date,\n",
    "    after_date = after_date)\n",
    "\n",
    "useful_models = ensemble_model.find_useful_models()\n",
    "\n",
    "split_seed = [get_seed_results(model_dir) for model_dir in useful_models]\n",
    "print(f'There is/are {len(set(split_seed))} unique split seeds used for these models '\\\n",
    "    'if this is more than 1 then the ensemble model metrics can be ignored')\n",
    "split_seed = split_seed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "retired-smile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the training data with the tag to say whether the grant\n",
    "# was used in the training or not\n",
    "old_ensemble_results = old_ensemble_results[['Internal ID', 'How has this grant been used before?', 'Ensemble predictions - 3 models']]\n",
    "training_data = pd.merge(training_data, old_ensemble_results, how = 'left', on = ['Internal ID'])\n",
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "confirmed-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process grants data for predicting\n",
    "training_data = clean_grants_data(training_data)\n",
    "training_data['Grant texts'] = training_data[['Title', 'Grant Programme:Title', 'Description']].agg(\n",
    "            '. '.join, axis=1\n",
    "            ).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "executive-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data[['Internal ID', 'Relevance code',\n",
    "                               'Grant texts', 'Ensemble predictions - 3 models', 'How has this grant been used before?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adolescent-cable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Relevance code</th>\n",
       "      <th>Grant texts</th>\n",
       "      <th>Ensemble predictions - 3 models</th>\n",
       "      <th>How has this grant been used before?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106169/Z/14/Z</td>\n",
       "      <td>1</td>\n",
       "      <td>A UK Hub to Catalyse Open Target Discovery.. S...</td>\n",
       "      <td>1</td>\n",
       "      <td>Training data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213494/Z/18/Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Spatiotemporal dynamics of arbovirus transmiss...</td>\n",
       "      <td>0</td>\n",
       "      <td>Test data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Internal ID  Relevance code  \\\n",
       "0  106169/Z/14/Z               1   \n",
       "1  213494/Z/18/Z               1   \n",
       "\n",
       "                                         Grant texts  \\\n",
       "0  A UK Hub to Catalyse Open Target Discovery.. S...   \n",
       "1  Spatiotemporal dynamics of arbovirus transmiss...   \n",
       "\n",
       "   Ensemble predictions - 3 models How has this grant been used before?  \n",
       "0                                1                        Training data  \n",
       "1                                0                            Test data  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bound-candle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only care about the grants not in the training data\n",
    "training_data = training_data.loc[\n",
    "    (pd.notnull(training_data['Relevance code'])) & (\n",
    "        training_data['How has this grant been used before?'] != 'Training data')]\n",
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "imperial-brisbane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Grant texts</th>\n",
       "      <th>Ensemble predictions - 3 models</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevance code</th>\n",
       "      <th>How has this grant been used before?</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>Test data</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unseen data</th>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>Test data</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unseen data</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Internal ID  Grant texts  \\\n",
       "Relevance code How has this grant been used before?                             \n",
       "0              Test data                                      15           15   \n",
       "               Unseen data                                   304          304   \n",
       "1              Test data                                      55           55   \n",
       "               Unseen data                                   133          133   \n",
       "\n",
       "                                                     Ensemble predictions - 3 models  \n",
       "Relevance code How has this grant been used before?                                   \n",
       "0              Test data                                                          15  \n",
       "               Unseen data                                                       304  \n",
       "1              Test data                                                          55  \n",
       "               Unseen data                                                       133  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.groupby(['Relevance code', 'How has this grant been used before?']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extraordinary-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "grants_text = training_data['Grant texts'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "private-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for count_SVM_201022...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gallaghe/Code/nutrition-labels/build/virtualenv/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator SVC from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/gallaghe/Code/nutrition-labels/build/virtualenv/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for bert_SVM_scibert_201022...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 507/507 [09:48<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for bert_SVM_bert_201022...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gallaghe/Code/nutrition-labels/build/virtualenv/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator SVC from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "100%|██████████| 507/507 [10:08<00:00,  1.20s/it]\n",
      "/Users/gallaghe/Code/nutrition-labels/build/virtualenv/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for tfidf_log_reg_201022...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gallaghe/Code/nutrition-labels/build/virtualenv/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/gallaghe/Code/nutrition-labels/build/virtualenv/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Predict for each model\n",
    "_ = ensemble_model.predict(grants_text, useful_models)\n",
    "model_predictions_df = ensemble_model.model_predictions_df\n",
    "del model_predictions_df['Ensemble prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "legal-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_sums = model_predictions_df['Number of models agree tech grant']\n",
    "\n",
    "cutoff = 3\n",
    "\n",
    "training_data[f'New Ensemble predictions - {cutoff} models'] = [1 if pred_sum >= cutoff else 0 for pred_sum in prediction_sums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "purple-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training_data['Relevance code'].tolist()\n",
    "y_predict = training_data[f'New Ensemble predictions - {cutoff} models'].tolist()\n",
    "# Evaluate ensemble results\n",
    "scores = {\n",
    "        'accuracy': accuracy_score(y, y_predict),\n",
    "        'f1': f1_score(y, y_predict, average='binary'),\n",
    "        'precision_score': precision_score(y, y_predict, zero_division=0, average='binary'),\n",
    "        'recall_score': recall_score(y, y_predict, zero_division=0, average='binary'),\n",
    "        'Test classification report': classification_report(y, y_predict),\n",
    "        'Test confusion matrix': pretty_confusion_matrix(y, y_predict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "medical-approach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7337278106508875,\n",
       " 'f1': 0.5970149253731344,\n",
       " 'precision_score': 0.6802721088435374,\n",
       " 'recall_score': 0.5319148936170213,\n",
       " 'Test classification report': '              precision    recall  f1-score   support\\n\\n           0       0.76      0.85      0.80       319\\n           1       0.68      0.53      0.60       188\\n\\n    accuracy                           0.73       507\\n   macro avg       0.72      0.69      0.70       507\\nweighted avg       0.73      0.73      0.73       507\\n',\n",
       " 'Test confusion matrix':               predicted tag 0  predicted tag 1\n",
       " actual tag 0              272               47\n",
       " actual tag 1               88              100}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-camcorder",
   "metadata": {},
   "source": [
    "## Original model scores (on original test data only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "pediatric-marine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8691588785046729,\n",
       " 'f1': 0.8727272727272727,\n",
       " 'precision_score': 0.8727272727272727,\n",
       " 'recall_score': 0.8727272727272727,\n",
       " 'Test classification report': '              precision    recall  f1-score   support\\n\\n         0.0       0.87      0.87      0.87        52\\n         1.0       0.87      0.87      0.87        55\\n\\n    accuracy                           0.87       107\\n   macro avg       0.87      0.87      0.87       107\\nweighted avg       0.87      0.87      0.87       107\\n',\n",
       " 'Test confusion matrix':               predicted tag 0  predicted tag 1\n",
       " actual tag 0               45                7\n",
       " actual tag 1                7               48}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-draft",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
