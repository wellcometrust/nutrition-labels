{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0150dcf1",
   "metadata": {},
   "source": [
    "## Fairness over different groups\n",
    "How well does the model do on different subsets of the test data?\n",
    "- 360 giving data predictions\n",
    "- 42 data predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c3ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "618d000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gallaghe/Code/nutrition-labels\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68129b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gallaghe/Code/nutrition-labels/build/virtualenv/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "2021-04-29 11:30:31 wellcomeml.logger WARNING: If you want to use hdbscan you need to runpip3 install hdbscan --no-cache-dir --no-binary :all: --no-build-isolation Read more https://github.com/wellcometrust/WellcomeML/issues/197\n"
     ]
    }
   ],
   "source": [
    "from nutrition_labels.evaluate import merge_grants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2dc881",
   "metadata": {},
   "source": [
    "## Get grants data (title, description, year, organisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9677f8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16854"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant_data = pd.read_csv('data/raw/wellcome-grants-awarded-2005-2019.csv')\n",
    "grant_data.drop_duplicates(subset=['Internal ID'], inplace=True)\n",
    "len(grant_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e7de6",
   "metadata": {},
   "source": [
    "## Get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80a4a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_date = '210402'\n",
    "\n",
    "# To get ground truth:\n",
    "model_dir = f'models/{model_date}'\n",
    "model_name = f'bert_log_reg_{model_date}' # it doesn't actually matter which model you choose, since all ground truth is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a170fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info_file = f'{model_dir}/training_information.json'\n",
    "with open(training_info_file, 'r') as file:\n",
    "    for line in file:\n",
    "        model_data = json.loads(line)\n",
    "        model_name = list(model_data.keys())[0]\n",
    "        if model_name==model_name:\n",
    "            raw_test_data = [(grant_id, m['Truth']) for grant_id, m in model_data[model_name].items() if m['Test/train']=='Test']\n",
    "            raw_train_data = [(grant_id, m['Truth']) for grant_id, m in model_data[model_name].items() if m['Test/train']=='Train']\n",
    "            break\n",
    "raw_test_data = pd.DataFrame(raw_test_data, columns = ['Reference', 'Truth'])\n",
    "raw_train_data = pd.DataFrame(raw_train_data, columns = ['Reference', 'Truth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd3649",
   "metadata": {},
   "source": [
    "## Merge with 360 giving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87865995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16914"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get predictions:\n",
    "predictions_date = '210406'\n",
    "model_360_preds = pd.read_csv(f'data/processed/predictions/{predictions_date}/wellcome-grants-awarded-2005-2019_tagged.csv')\n",
    "len(model_360_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc8efbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_360_preds.rename({'Tech grant prediction': 'Tech grant 360 prediction', 'Grant ID': 'Grant ID 1'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b989fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Tech grant 360 prediction</th>\n",
       "      <th>Grant ID 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103709/Z/14/A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>103709/Z/14/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202571/Z/16/Z</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>202571/Z/16/Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reference  Truth  Tech grant 360 prediction     Grant ID 1\n",
       "0  103709/Z/14/A      1                          1  103709/Z/14/A\n",
       "1  202571/Z/16/Z      1                          1  202571/Z/16/Z"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.merge(\n",
    "            raw_test_data,\n",
    "            model_360_preds.drop_duplicates(subset=['Grant ID 1']),\n",
    "            how=\"left\",\n",
    "            left_on='Reference',\n",
    "            right_on='Grant ID 1'\n",
    "        )\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0173a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label_name = 'Truth'\n",
    "test_data = merge_grants(\n",
    "    test_data,\n",
    "    grant_data,\n",
    "    'Grant ID 1',\n",
    "    'Internal ID',\n",
    "    training_label_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dce95be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d01f6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.merge(\n",
    "            raw_train_data,\n",
    "            model_360_preds.drop_duplicates(subset=['Grant ID 1']),\n",
    "            how=\"left\",\n",
    "            left_on='Reference',\n",
    "            right_on='Grant ID 1'\n",
    "        )\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdf42fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n"
     ]
    }
   ],
   "source": [
    "training_label_name = 'Truth'\n",
    "train_data = merge_grants(\n",
    "    train_data,\n",
    "    grant_data,\n",
    "    'Grant ID 1',\n",
    "    'Internal ID',\n",
    "    training_label_name\n",
    ")\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d37f42a",
   "metadata": {},
   "source": [
    "## Merge with 42 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a4f928f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126341"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get predictions:\n",
    "predictions_date = '210403'\n",
    "model_42_preds = pd.read_csv(f'data/processed/predictions/{predictions_date}/all_grants_fortytwo_info_210420_tagged.csv')\n",
    "len(model_42_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a08f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_42_preds.rename({'Tech grant prediction': 'Tech grant 42 prediction', 'Grant ID': 'Grant ID 2'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "378752ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.merge(\n",
    "            test_data,\n",
    "            model_42_preds.drop_duplicates(subset=['Grant ID 2']),\n",
    "            how=\"left\",\n",
    "            left_on='Reference',\n",
    "            right_on='Grant ID 2'\n",
    "        )\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ab78efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(test_data['Tech grant 360 prediction']== test_data['Tech grant 42 prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd1addd",
   "metadata": {},
   "source": [
    "## Evaluate fairness\n",
    "All the predictions are the same, so the fairness results will be the same for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e0c8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found by manually looking at the list in the test data (so might not be conclusive!)\n",
    "golden_triangle = [\n",
    "    'University College London', 'Imperial College London', \"King's College London\",\n",
    "    'University of Oxford',\n",
    "    'University of Cambridge',\n",
    "    'Exeter College Oxford'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47ae501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data_cols(test_data, golden_triangle):\n",
    "    # Golden triangle or not\n",
    "    test_data['Recipient organisation'] = ['Golden triangle' if org in golden_triangle else 'Not golden triangle' for org in test_data['Recipient Org:Name']]\n",
    "\n",
    "    # Greater london, international or not\n",
    "    region_grouped = []\n",
    "    for region in test_data['Region']:\n",
    "        if region == 'Greater London':\n",
    "            region_grouped.append('Greater London')\n",
    "        elif region == 'International':\n",
    "            region_grouped.append('International')\n",
    "        else:\n",
    "            region_grouped.append('UK, not greater London')\n",
    "    test_data['Region grouped'] = region_grouped\n",
    "\n",
    "    test_data['Recipient Org:Country grouped'] = ['UK' if g=='United Kingdom' else 'Not UK' for g in test_data['Recipient Org:Country']]\n",
    "\n",
    "    test_data['Financial Year grouped'] = [\n",
    "        '<2010' if int(g[0:4])<2010 else (\n",
    "            '2010-2015' if int(g[0:4])<2015 else (\n",
    "            '2015-2017' if int(g[0:4])<2017 else '>=2017')\n",
    "        ) for g in test_data['Financial Year']]\n",
    "\n",
    "    test_data['Description length'] = test_data['Description'].agg(lambda x: len(x))\n",
    "    bins = [0,1000, 1250,1500, 2000, 3000, 4000]\n",
    "    test_data['Description length binned'] = pd.cut(test_data['Description length'], bins)\n",
    "\n",
    "    test_data['Title length'] = test_data['Title'].agg(lambda x: len(x))\n",
    "    bins = [0,250, 500,750, 1000, 2000]\n",
    "    test_data['Title length binned'] = pd.cut(test_data['Title length'], bins)\n",
    "\n",
    "    test_data[\"Title plus Description\"] = test_data[\"Title\"] + ' ' + test_data[\"Description\"]\n",
    "    test_data[\"Title plus Description length\"] = test_data[\"Title plus Description\"].agg(lambda x: len(x))\n",
    "    bins = [0,1000, 1500, 2000, 3000, max(test_data[\"Title plus Description length\"])]\n",
    "    test_data['Title plus Description length binned'] = pd.cut(test_data['Title plus Description length'], bins)\n",
    "\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b371f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = group_data_cols(test_data, golden_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67090d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = group_data_cols(train_data, golden_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c205e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = [\n",
    "    'Recipient organisation',\n",
    "    'Region grouped',\n",
    "    'Recipient Org:Country grouped',\n",
    "    'Financial Year grouped',\n",
    "    'Title plus Description length binned',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16c25aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_data(data, pred_col):\n",
    "    y = data['Truth'].tolist()\n",
    "    y_predict = data[pred_col].tolist()\n",
    "    scores = {\n",
    "            'Sample size': len(data),\n",
    "            'accuracy': accuracy_score(y, y_predict),\n",
    "            'f1': f1_score(y, y_predict, average='binary'),\n",
    "            'precision_score': precision_score(y, y_predict, zero_division=0, average='binary'),\n",
    "            'recall_score': recall_score(y, y_predict, zero_division=0, average='binary')}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dbdcbb15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction type</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Type</th>\n",
       "      <th>Train proportion in this class</th>\n",
       "      <th>Test proportion true</th>\n",
       "      <th>Sample size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Recipient organisation</td>\n",
       "      <td>Golden triangle</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.580</td>\n",
       "      <td>69</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Recipient organisation</td>\n",
       "      <td>Not golden triangle</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.455</td>\n",
       "      <td>88</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Region grouped</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.559</td>\n",
       "      <td>59</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Region grouped</td>\n",
       "      <td>International</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.417</td>\n",
       "      <td>12</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.833</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Region grouped</td>\n",
       "      <td>UK, not greater London</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.488</td>\n",
       "      <td>86</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Recipient Org:Country grouped</td>\n",
       "      <td>Not UK</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.400</td>\n",
       "      <td>15</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Recipient Org:Country grouped</td>\n",
       "      <td>UK</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.521</td>\n",
       "      <td>142</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Financial Year grouped</td>\n",
       "      <td>2010-2015</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.479</td>\n",
       "      <td>48</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Financial Year grouped</td>\n",
       "      <td>2015-2017</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.489</td>\n",
       "      <td>45</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.880</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Financial Year grouped</td>\n",
       "      <td>&lt;2010</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.250</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Financial Year grouped</td>\n",
       "      <td>&gt;=2017</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.589</td>\n",
       "      <td>56</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Title plus Description length binned</td>\n",
       "      <td>(0, 1000]</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.250</td>\n",
       "      <td>12</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Title plus Description length binned</td>\n",
       "      <td>(1000, 1500]</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.493</td>\n",
       "      <td>67</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Title plus Description length binned</td>\n",
       "      <td>(1500, 2000]</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.552</td>\n",
       "      <td>67</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Title plus Description length binned</td>\n",
       "      <td>(2000, 3000]</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.667</td>\n",
       "      <td>9</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.909</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tech grant 360 prediction</td>\n",
       "      <td>Title plus Description length binned</td>\n",
       "      <td>(3000, 3798]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Prediction type                             Data type  \\\n",
       "0   Tech grant 360 prediction                Recipient organisation   \n",
       "1   Tech grant 360 prediction                Recipient organisation   \n",
       "2   Tech grant 360 prediction                        Region grouped   \n",
       "3   Tech grant 360 prediction                        Region grouped   \n",
       "4   Tech grant 360 prediction                        Region grouped   \n",
       "5   Tech grant 360 prediction         Recipient Org:Country grouped   \n",
       "6   Tech grant 360 prediction         Recipient Org:Country grouped   \n",
       "7   Tech grant 360 prediction                Financial Year grouped   \n",
       "8   Tech grant 360 prediction                Financial Year grouped   \n",
       "9   Tech grant 360 prediction                Financial Year grouped   \n",
       "10  Tech grant 360 prediction                Financial Year grouped   \n",
       "11  Tech grant 360 prediction  Title plus Description length binned   \n",
       "12  Tech grant 360 prediction  Title plus Description length binned   \n",
       "13  Tech grant 360 prediction  Title plus Description length binned   \n",
       "14  Tech grant 360 prediction  Title plus Description length binned   \n",
       "15  Tech grant 360 prediction  Title plus Description length binned   \n",
       "\n",
       "                      Type  Train proportion in this class  \\\n",
       "0          Golden triangle                           0.371   \n",
       "1      Not golden triangle                           0.629   \n",
       "2           Greater London                           0.311   \n",
       "3            International                           0.090   \n",
       "4   UK, not greater London                           0.599   \n",
       "5                   Not UK                           0.113   \n",
       "6                       UK                           0.887   \n",
       "7                2010-2015                           0.275   \n",
       "8                2015-2017                           0.324   \n",
       "9                    <2010                           0.068   \n",
       "10                  >=2017                           0.333   \n",
       "11               (0, 1000]                           0.064   \n",
       "12            (1000, 1500]                           0.409   \n",
       "13            (1500, 2000]                           0.435   \n",
       "14            (2000, 3000]                           0.070   \n",
       "15            (3000, 3798]                           0.000   \n",
       "\n",
       "    Test proportion true  Sample size  accuracy     f1  precision_score  \\\n",
       "0                  0.580           69     0.913  0.925            0.925   \n",
       "1                  0.455           88     0.886  0.875            0.875   \n",
       "2                  0.559           59     0.932  0.937            0.968   \n",
       "3                  0.417           12     0.917  0.909            0.833   \n",
       "4                  0.488           86     0.872  0.871            0.860   \n",
       "5                  0.400           15     0.933  0.923            0.857   \n",
       "6                  0.521          142     0.894  0.898            0.904   \n",
       "7                  0.479           48     0.833  0.800            0.941   \n",
       "8                  0.489           45     0.933  0.936            0.880   \n",
       "9                  0.250            8     1.000  1.000            1.000   \n",
       "10                 0.589           56     0.911  0.928            0.889   \n",
       "11                 0.250           12     0.917  0.857            0.750   \n",
       "12                 0.493           67     0.866  0.862            0.875   \n",
       "13                 0.552           67     0.925  0.933            0.921   \n",
       "14                 0.667            9     0.889  0.909            1.000   \n",
       "15                 0.500            2     1.000  1.000            1.000   \n",
       "\n",
       "    recall_score  \n",
       "0          0.925  \n",
       "1          0.875  \n",
       "2          0.909  \n",
       "3          1.000  \n",
       "4          0.881  \n",
       "5          1.000  \n",
       "6          0.892  \n",
       "7          0.696  \n",
       "8          1.000  \n",
       "9          1.000  \n",
       "10         0.970  \n",
       "11         1.000  \n",
       "12         0.848  \n",
       "13         0.946  \n",
       "14         0.833  \n",
       "15         1.000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_results = []\n",
    "for column in data_types:\n",
    "    for pred_col in ['Tech grant 360 prediction']:\n",
    "        result = test_data.groupby(column).apply(lambda x: evaluate_data(x, pred_col)).to_dict()\n",
    "        for column_type, type_results in result.items():\n",
    "            this_test_data = test_data[test_data[column]==column_type]\n",
    "            column_results = {\n",
    "                'Prediction type': pred_col,\n",
    "                'Data type': column,\n",
    "                'Type': column_type,\n",
    "                'Train proportion in this class': sum(train_data[column]==column_type)/len(train_data),\n",
    "                'Test proportion true': sum(this_test_data['Truth']==1)/len(this_test_data)\n",
    "            }\n",
    "            for metric, value in type_results.items():\n",
    "                column_results[metric] = value\n",
    "            fairness_results.append(column_results)\n",
    "\n",
    "fairness_results_df = pd.DataFrame(fairness_results).round(3)\n",
    "fairness_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ecfbe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_results_df.to_csv(f'data/processed/fairness/fairness_results_{model_date}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55d40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
