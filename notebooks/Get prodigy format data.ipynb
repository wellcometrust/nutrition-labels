{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "piano-mystery",
   "metadata": {},
   "source": [
    "# Data formate suitable for Prodigy \n",
    "1. All the data for tagging (source data) for prodigy needs to be in jsonl\n",
    "2. Convert original training data into the correct format for db-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "isolated-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "provincial-insurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gallaghe/Code/nutrition-labels\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aquatic-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nutrition_labels.useful_functions import remove_useless_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dressed-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The list of grants in the original training data \n",
    "# training_data = pd.read_csv('data/processed/training_data/210126/training_data.csv')\n",
    "# training_data_grants = training_data['Internal ID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spread-russian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16914"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grant data inc descriptions\n",
    "original_grant_data = pd.read_csv('data/raw/wellcome-grants-awarded-2005-2019.csv')\n",
    "len(original_grant_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "possible-nursery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14613"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble results - so we know which data points were in train/test split\n",
    "ensemble_results = pd.read_csv('data/processed/ensemble/210129_all_ensemble_results.csv')\n",
    "ensemble_results = ensemble_results[['Internal ID', 'How has this grant been used before?', 'Ensemble predictions - 3 models']]\n",
    "len(ensemble_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "simplified-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "grant_text_cols = ['Title', 'Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-asian",
   "metadata": {},
   "source": [
    "### 1. All the data for tagging (source data) for prodigy needs to be in jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "worldwide-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "grant_data = original_grant_data.copy()\n",
    "grant_data.fillna('', inplace=True)\n",
    "grant_data[grant_text_cols] = grant_data[grant_text_cols].applymap(\n",
    "    remove_useless_string\n",
    "    )\n",
    "\n",
    "grant_data = grant_data[grant_data['Description'] != 'Not available']\n",
    "grant_data.dropna(subset=['Description'], inplace=True)\n",
    "grant_data.drop_duplicates('Internal ID', inplace=True)\n",
    "    \n",
    "grant_data['text'] = grant_data[grant_text_cols].agg(\n",
    "        '. '.join, axis=1\n",
    "        ).tolist()\n",
    "\n",
    "grant_data['id'] = grant_data['Internal ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "demanding-valentine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14613"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grant_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "becoming-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grant_data[['id','text']].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "organizational-riverside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14613"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "minimal-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/prodigy/grants_data.jsonl', 'w') as json_file:\n",
    "    for entry in result:\n",
    "        json.dump(entry, json_file)\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-network",
   "metadata": {},
   "source": [
    "### 2. Convert original training data into the correct format for db-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abroad-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "grant_data = pd.merge(grant_data, ensemble_results, how = 'left', on = ['Internal ID'])\n",
    "grant_data['score'] = [0.5]*len(grant_data)\n",
    "grant_data['label'] = [\"Tech grant\" if label==1.0 else \"Not tech grant\" for label in grant_data['Ensemble predictions - 3 models'].tolist()]\n",
    "\n",
    "training_split_data = grant_data.loc[grant_data['How has this grant been used before?'] == 'Training data'].reset_index()\n",
    "test_split_data = grant_data.loc[grant_data['How has this grant been used before?'] == 'Test data'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bacterial-suggestion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not tech grant    281\n",
       "Tech grant        239\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_split_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "incoming-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_formatted = training_split_data[['id', 'text', 'score', 'label']].to_dict(orient=\"records\")\n",
    "test_split_formatted = test_split_data[['id', 'text', 'score', 'label']].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "marine-resource",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '219414/Z/19/Z',\n",
       " 'text': 'Whole Genome Sequencing (WGS) of 450,000 UK Biobank Samples. Large-scale WGS of the UK Biobank cohort to generate and evaluate therapeutic hypotheses regarding targets, biomarkers and pathways implicated in disease',\n",
       " 'score': 0.5,\n",
       " 'label': 'Tech grant'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split_formatted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "encouraging-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/prodigy/existing_training_data.jsonl', 'w') as json_file:\n",
    "    for entry in train_split_formatted:\n",
    "        json.dump(entry, json_file)\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "vocational-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/prodigy/existing_test_data.jsonl', 'w') as json_file:\n",
    "    for entry in test_split_formatted:\n",
    "        json.dump(entry, json_file)\n",
    "        json_file.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
