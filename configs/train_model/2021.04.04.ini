[DEFAULT]
version = 2021.04.04
description = Just train a bert + log reg model since after experimentation this was better than any other, or ensemble of other, models. Train using the 210308 training data, and use the grant text data from 360Giving, don't include grant type. When vectorizer isn't trained on all data.

[data]
training_data_file = data/processed/training_data/210308/training_data.csv
label_name = Relevance code
training_data_file_id = Internal ID
prediction_cols = ['Title', 'Description']
grants_text_data_file = data/raw/wellcome-grants-awarded-2005-2019.csv
grants_text_data_file_id = Internal ID

[models]
vectorizer_types = ['bert']
classifier_types = ['log_reg']

[params]
relevant_sample_ratio = 1
test_size = 0.25
split_seed = 1
